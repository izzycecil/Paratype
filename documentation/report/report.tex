% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------

\documentclass{acm_proc_article-sp}
\usepackage{lmodern} % font problem fix

\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{float,dblfloatfix,fixltx2e}
\usepackage[format=plain,font=small,labelfont=bf]{caption}
\usepackage[utf8]{inputenc}
% noitemsep option for enumerate and itemize
\usepackage{enumitem}

% typesetting algorithms
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage[section]{algorithm}

% grammar?
\usepackage{syntax, etoolbox}
\AtBeginEnvironment{grammar}{\small}
\setlength{\grammarparsep}{8pt plus 1pt minus 1pt}
\setlength{\grammarindent}{12em}

% real code
\usepackage{listings,color,xcolor}
\usepackage{lstlang0} % go
\definecolor{dkgreen}{rgb}{0,0.6,0}
\usepackage{MnSymbol}
\lstset{
	prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\rhookswarrow}},
	postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\rcurvearrowse\space}},
	breaklines=true,
	numbers=left,
	numberstyle=\scriptsize,
	breakatwhitespace=true,
	frame=single,
%	frameround=tttt,
	tabsize=4,
	showstringspaces=false,
	aboveskip=1.8em,
	belowskip=0em,
	captionpos=b,
	xleftmargin=0.4em,
	xrightmargin=0em,
	keywordstyle=\bfseries\color{dkgreen},
	commentstyle=\itshape\color{purple},
	identifierstyle=\color{black},
	stringstyle=\color{blue},
	basicstyle=\small\ttfamily
}

\lstdefinelanguage{Paratype}{
	morekeywords={func,inherits,implements,throws,type,typeclass,constrain,to},
}

\begin{document}

\title{Paratype --- A Parallel Type Completion System}


% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
\numberofauthors{3}
\author{
\alignauthor
Tyler Cecil\\
       \affaddr{New Mexico Tech}\\
       \affaddr{801 Leroy Place}\\
       \affaddr{Socorro, NM 87801 USA}\\
       \email{tcecil@nmt.edu}
\alignauthor
Ben Turrubiates\\
       \affaddr{New Mexico Tech}\\
       \affaddr{801 Leroy Place}\\
       \affaddr{Socorro, NM 87801 USA}\\
       \email{bturrubi@nmt.edu}
\alignauthor
Christopher Koch\\
       \affaddr{New Mexico Tech}\\
       \affaddr{801 Leroy Place}\\
       \affaddr{Socorro, NM 87801 USA}\\
       \email{ckoch@cs.nmt.edu}
}
\date{\today}

\maketitle
\begin{abstract}
  In the following report we introduce \emph{Paratype}, an actor model of
  type completion. Type analysis of modern languages such as
  Haskell, Agda, and Coq can be an intense stage in compilation. % CITE
  With the use
  of an actor model, we may cut down compilation time as well as open up
  doors for new models of type evaluation. Working on a grammar with bounded
  parametric polymorphism, Paratype communicates types across a large call
  graph to resolve type errors, append errors, and evaluate types in parallel.
  To minimize message overhead, we have used a shared memory message
  passing system. We believe our actor approach significantly
  speeds up the compilation process and it may apply to some other interesting
  problems.
\end{abstract}

\category{F.3.3}{Studies of Program Constructs}{Type structure}
\category{D.3.3}{Programming Languages}{Language Constructs and Features}
\category{D.3.4}{Programming Languages}{Processors}

% some out of 16 general terms!
\terms{Design, Languages, Performance}

\keywords{type theory, language theory, type completion, type checking, type
inference, code analysis, parallel, actor model}

\section{Introduction}

% problem and why important
% compilers: e.g. just-in-time comp

``Compile one time, run many times: that means compilers do not need to be
fast, right?'' Luckily, no software engineer thinks this way. In fact,
compilation speed is a concern of many budding languages. Aside from lexing,
typically the slowest part of compilation, modern
languages spend an embarrassing amount of time resolving
types. % CITE (tyler)
Principally, this is due to the adoption of the
\emph{System F} formalization in modern strongly typed languages. Moreover,
many languages have type inference or even type bounds, further complicating
the process. Unfortunately, type evaluation serves as the foundation for
automated theorem provers and other logic analysis systems. Even within the
compilation domain, interpreted languages and JIT languages need type
resolution much faster than is currently being provided. Type evaluation needs
to be expedited.

To achieve this, we have developed \emph{Paratype}: an actor model of
type evaluation. As will be apparent shortly, most type evaluation procedures
can be described as a conversation between functions. Each function
communicates information about its type to ``neighboring'' functions. As the
chatter subsides, we are left with all functions knowing their types or a
function knowing that it cannot compile. Most systems involve walking through
the tree of this conversation. Using a shared memory message passing system,
\emph{Paratype} allows functions to be actors and lets the conversation
happen.

At the moment, we are only using a toy grammar that is defined in the
proposal. Our grammer includes types of normal variables, and error types in
order to cover most use cases in modern type systems. Perhaps one day
\emph{Paratype} can be integrated into a project such as the Haskell
compiler \texttt{ghc}.

\section{Problem Definition}
\label{sec:problem}
% grammar, input/output, type completion, lambda calculus (System F)

Formally, our problem will be to take an input file of a specified grammar and
generate an output of either failure due to undecidability or the same file
with multiple implementations of each function for each set of explicit types
instead of type variables. In the process of doing this, we will also be
performing type checking. The goal is to find an explicit type for
each function call without type conflicts.

We define a few terms to use throughout the proposal:
\begin{description}
	\item[Type] A set of values. Types may implement type classes.
	\item[Type class] A set of types. Type classes may inherit other type classes.
	\item[Context] The set of explicit types and metainformation associated
		with a function call: caller, parameter types, return type.
	\item[Resolution] Resolving a context means giving it explicit types.
	\item[Parent (function)] Caller of a function.
	\item[Child (function)] A function that is called by its parent function.
	\item[Type variable] A variable that ranges over types. A type variable may
		be constrained to zero or more type classes.
	\item[Parametric polymorphism] A way to allow a language to express the
		handling of functions and types homogeneously independent of their type
		through the use of generic functions, also known as generic
		programming.
	\item[Bounded parametric polymorphism] A method of providing extra
		information about a generic data type. In Haskell, this is achieved by
		creating a type class which types may implement.
\end{description}

Listing~\ref{lst:informalg} shows an informal example of our grammar. It is a
grammar for a simple functional language that provides bounded parametric
polymorphism through type classes. This allows expressing functions in terms of
generic types while still maintaining the same behavior. This use of type
variables introduces the need for partial contexts.

\begin{lstlisting}[caption=Grammar displayed informally,language=Paratype,label=lst:informalg]
typeclass Arithmetic
typeclass Num inherits Arithmetic

type int implements Num
type float implements Num

func foo(int, T, R) float throws errorType
    = bar(baz(T), R, int)
\end{lstlisting}

An example of a partial context is shown in Listing~\ref{lst:cbyparent}. The
function \lstinline!bar! is declared as accepting and returning a \lstinline!T!
type.  This introduces a partial context due to \lstinline!T! being a type
variable. The parameter type for \lstinline!bar! is provided by its parent
function \lstinline!foo!. This also completes the return type of
\lstinline!bar!.

\begin{lstlisting}[caption=Explicit context provided by parent,language=Paratype,label=lst:cbyparent]
func foo(int x, int y) int
    = bar(y)

func bar(T d) T
    = T
\end{lstlisting}

Types for partial contexts can be provided by both the parent and the child.
Consider the example shown in Listing~\ref{lst:cbychild}. Function
\lstinline!foo!  is defined as returning an \lstinline!R! type. The function
definition contains the result of calling \lstinline!bar! as the return value.
\lstinline!bar! is defined as having an \lstinline!int! return type. Since
\lstinline!foo! returns the value of calling \lstinline!bar! it also has a
return type of \lstinline!int!.

\begin{lstlisting}[caption=Explicit context provided by child,language=Paratype,label=lst:cbychild]
func foo(T a, S b) R
    = bar(a, b)

func bar(float a, float b) int
    = int
\end{lstlisting}

In the previous examples all partial contexts have been resolved by either the
parent or the child. There are situations where they can mutually provide
contexts for each other. One example of this is shown in
Listing~\ref{lst:cbyboth}. In this example \lstinline!foo! is providing
the type of the second parameter for function \lstinline!barbar!.
\lstinline!barbar!  also provides the type of the first parameter for function
\lstinline!foo!. Notice that function \lstinline!barbar! is defined as
returning a type variable \lstinline!R!. Since \lstinline!foo! returns an
\lstinline!int! type and its return value is a call to \lstinline!barbar!; this
resolves the return type for \lstinline!barbar!. The evaluation of these
partial contexts is a non-trivial task.

\begin{lstlisting}[caption=Explicit context provided by child and parent,language=Paratype,label=lst:cbyboth]
func foo(T a, int b) int
    = barbar(a, b)

func barbar(int a, T b) R
    = R
\end{lstlisting}

Another problem that type variables introduce is the need to maintain partial
contexts. Multiple fully evaluated contexts may exist in the end and may not be
the result of type errors. An example of this is shown in
Listing~\ref{lst:partial}. The \lstinline!bar! function accepts a type variable
\lstinline!b! as an input parameter. The function \lstinline!foo! provides a
context for \lstinline!bar! in which \lstinline!b! is of type \lstinline!int!.
At this point \lstinline!bar! now has a fully evaluated context, but
\lstinline!baz! can also complete the partial context with \lstinline!b!
resolving to type \lstinline!float!.  In this situation these are both valid
and should not be considered a type error.

\begin{lstlisting}[caption=Need to maintain partial contexts,language=Paratype,label=lst:partial]
func foo(int x) T
    = bar(x)

func bar(T b) char
    = char

func baz(float b) T
    = bar(b)
\end{lstlisting}

Although contexts can be provided by both the parent and the child, there are
situations where there is not enough information to resolve a context. Consider
Listing~\ref{lst:unhalting}: \lstinline!bar! accepts a type variable as a
parameter. The context provided by its calling function \lstinline!foo!
resolves the parameter as being the local variable \lstinline!b!. This is
problematic due to \lstinline!b! also being a type variable. In this example
there is not enough information to resolve a full context for either
\lstinline!bar! or \lstinline!foo!.

\begin{lstlisting}[caption=Unhalting context resolution,language=Paratype,label=lst:unhalting]
func foo(T b) int
    = bar(b)

func bar(T a) int
    = int
\end{lstlisting}

Introducing errors into the grammar adds more complexity since they need to
propagate up the call stack. In the example shown in Listing~\ref{lst:errors},
all parent functions of \lstinline!bar! need to have \lstinline!weirdError! in
their fully resolved contexts.

\begin{lstlisting}[caption=Errors,language=Paratype,label=lst:errors]
func foobar(T b) T
    = foo(b)

func foo(int b) int
    = bar(b)

func bar(T a) T throws weirdError
    = T
\end{lstlisting}

% ADD EXAMPLE OF NESTED FUNCTIONS

\section{Parallelization}

This is what each function $f$ does during its runtime:
\begin{enumerate}[noitemsep]
	\item Receive path-context object $(P, C_h)$ from parent $g$
	\item Set to running state
	\item Merge type information from $C_f$ into $C_h$
	\item Add $f$ to path $P$ and send $(P, C_h)$ to $f$'s child
	\item Waiting state
\end{enumerate}

Merging type information from $C_f$ into $C_h$ is a tricky task. There are two
cases:
\begin{enumerate}
	\item If $h$ is a direct parent of $f$, the function call from $h$ to $f$
		can be matched to $f$'s declaration.

		$f$ will override the type
		variables of that function call with the ones generated through its
		declaration and remember which ones it replaced by storing them in a
		map (called the type variable map).

		It will then override the type variables of $h$ that were used in the
		call to $f$ as well. $f$ knows which ones to replace: if a type
		variable in the declaration of $h$ is a key in its type variable map,
		it will replace it with the corresponding value.
	\item If $h$ is not a direct parent of $f$, we will simply use the type
		variable map created through direct parents of $f$ as detailed
		previously to replace any type variables in $h$.
\end{enumerate}

Ultimately, this allows type variables from the leaf nodes of the call graph to
``trickle up'' through the nodes until finally, the roots of the call graph and
every node in between is related to a leaf.




\section{Methods}

% Google Go and why

Due to the actor model, the problem lends itself nicely to a distributed memory
approach; however, it is usually commodity hardware that is used for
compilation. Therefore, used Google Go due to its concept of
\texttt{goroutines}. A \texttt{goroutine} is a lightweight thread that is
managed by the Go runtime.

\begin{lstlisting}[caption=Small \texttt{goroutine} example with
\texttt{channels},language=Go,label=lst:goroutine]
func node(name string, c chan string) {
	fmt.Println("I'm node ", name)
	/* send message to c
	 * (blocks until receiver is ready)
	 */
	c <- strings.Join(name, " has a message for you.")
}

func main() {
	// unbuffered channel
	c := make(chan string)
	go node("abc", c)
	// receive message from c (blocks)
	a := <-c
	fmt.Println(a)
}
\end{lstlisting}

It is possible to pass references through shared memory, called
\texttt{channels}, with \texttt{goroutines}: like message passing in shared
memory. This can be seen in Listing~\ref{lst:goroutine}. Of course, unlike in
the example, the channel may also be buffered and would thus only block sending
when the buffer is full and receiving when the buffer is empty. This is one of
the reasons that we chose Google Go: it allows us to use message passing
with a high degree of flexibility without the overhead of actually sending the message.

% TODO: talk about interesting go features like WaitGroups etc
% TODO: was Go a good idea?

The \texttt{goroutines} fit the actor model of type resolution nicely since
the threads are lightweight and communication is easy to arrange. We found ourselves taking advantage of the fact that messages sent and received through \texttt{channels} are actually references to shared memory. This way, a specific context will update everywhere that it
is referenced and we must only notify other actors that something changed
instead of sending the context again. This reduces communication overhead while
still functioning as a message passing system.

Go also provides concurrency features that are useful for managing state. One of these concurrency primitives is the \texttt{WaitGroup}. A WaitGroup is similar to a semaphore. All of the threads are given a pointer to the WaitGroup upon their creation. The WaitGroup then provides basic functionality such as \lstinline!WaitGroup.Add()! and \lstinline!WaitGroup.Done()!. The add method increments a counter in the WaitGroup. When the WaitGroup contains a non-zero number all of the threads that called \lstinline!WaitGroup.Wait()! are blocked. Invoking the done method simply decrements the counter. This has proved useful for managing the state of the threads.

% TODO : Discuss Clojure as a viable alternative and analyze whether the decision to use Go was the correct one.

Although Go provides nice concurrency features, we sometimes found ourselves fighting with the type system and verbosity of the language. Another consideration for the implementation was \texttt{Clojure}. Clojure is a lisp variant that runs on the Java Virtual Machine. There is a library for Clojure, \texttt{core.async}, which implements most of the concurrency features modeled after the Go concurrency system. This brings the same shared memory channels with the advantages of the concise and dynamic nature of Clojure. Clojure is also built for concurrency boasts immutable data types to provide safety in parallelized code. One of the issues with this is that Paratype is a very state driven application. This could lead to performance faults when using a language that is not built for modeling mutable state.

\section{Problems Induced by Parallelization}
	\subsection{Making Halting Deterministic}
		An issue when performing the type completion and analysis in parallel is knowing when all of the operations are completed and halting can commence. Halting in the initial implementation of Paratype was simple but not effective. Each of the functions spawned was added to a \texttt{WaitGroup}. At the start of every actors go loop they would mark themselves active by incrementing the WaitGroup. Once they reached the end of their go loop they would decrement the WaitGroup marking themselves inactive. This happened repeatedly in a loop. The main function would then wait for all actors to become inactive. If they were all inactive it would check if all of the channels were empty. This worked in some situations but had a race condition that would cause problems. The reason for this race condition is the state could change in between checking the WaitGroup and checking the channels.

		The updated iteration of halting requires keeping track of more state. Actors which do not have parents only need to send to their children and they are completed. The signaling of the completion is done through a flag in one of the communication messages. Once a child receives a message from its parent it processes the message. If the message contains a flag that indicates it is the last communication then the child sends a \lstinline!nil! value through the \lstinline!error! channel. This \lstinline!nil! value on the error channel is a message to the main thread that it can decrement the number of active processes. Once an actor is effectively inactive it is waiting for a message on the channel. This will never happen since its parent is also inactive. This provides an implicit barrier. Once the main thread sees that all functions have become inactive it sets a flag dictating that they collect their implementations and closes all of their channels.

% 		\begin{lstlisting}[caption=Communication Struct, language=Paratype, label=lst:commstruct]
% type Communication struct {
% 	Path		string
% 	Context		*Function
% 	Depth		int
% 	LastComm	bool
% 	Wait		*sync.WaitGroup
% }
% 		\end{lstlisting}
	\subsection{Halting On Type Error Detection}
		Even though an implementation for halting my work on valid input, it may fail for input which generate a type error. One of the advantages of performing the type checking process in parallel is that the type errors can be detected earlier. Once a type error is detected the threads must all exit gracefully. This is not a simple task due to the fact that goroutines can still perform writes on closed channels. Writes to closed channels will trigger a runtime error. A situation that is very common for input with type errors involves the main thread receiving an error and closing all of the channels. This means that the main threads needs to effectively communicate to all of the goroutines that they are done and should stop attempting to complete their contexts.

		The way this problem was approached involves adding two new variables to the actor. A WaitGroup signifying that execution should be paused and a boolean that signifies whether an actor should terminate itself. The WaitGroup is initially zero meaning that all goroutines which call wait can continue to execute without blocking on the call. This is important because all of the goroutines call wait before performing any writes to the channel. If an error is received then the main thread increments the WaitGroup. This pauses all of the threads before they can write to the channel. The main thread then iterates over all goroutines and sets the boolean that signifies that the thread should terminate. All of the goroutines then exit upon observing that the flag is set.
	\subsection{Function Composition}
		One of the issues induced by parallelization is the handling of function composition. Consider the code snippet shown in Listing ~\ref{lst:composition}
		\begin{lstlisting}[caption=Small Example of function composition, language=Paratype, label=lst:composition]
type int
type float
type boat
func f(A) boat
	= g(m(A), h(A), int)
func g(B, C, B) D
	= D
func m(int) A
	= A
func h(A) float
	= float
		\end{lstlisting}
		In the initial implementation of Paratype a function with no parents did not need to have a thread spawned for itself. Instead it would seed the children with its initial context. This became problematic when the implementation of function composition began. With this implementation the children would all evaluate their own contexts and replace values in the parents typevar map. This would cause the evaluation to be unresolvable due to inability to correctly map type variables. This was solved using a technique we refer to as ``in-out evaluation''.

\section{Analysis and Model}

 variables: number of functions, function calls, contexts, partial contexts,
 undecidability, number of physical cores available, number of types and
 type classes, etc

 gopp parser hangs in some cases (not our focus, so we don't care)

just some notes to use for empirical analysis later

 Complexity of f.Update(g) algorithm if g is parent of f:
 \[ U(f, g) = \sum_{\textrm{v in args of g and w replaces v}} V(v, w))
 \leq O(|\textrm{num args of g}| \times |\textrm{num typeclasses}|) \]

 UpdateTypevar (v and w merge to w):
 \[ V(v, w) = O(|\textrm{num of typeclasses on w}|) \]

 Complexity of f.Update(g) if g is parent of f:
 \[ \leq O(|\textrm{num atlas entries of g}| \times |\textrm{num typeclasses}|) \]

 All of these multiplied by hashmap access time at worst $O(\textrm{size of
 map})$ each

 how often is f.Update(g) called?

 -> context path object travels down every path!

 -> number of paths times number of nodes in each path

\section{Conclusion}

\appendix
\section{Finalized Grammar}

\section{Team Members and Their Contributions}

\section{Things Learnt From This Project}

\end{document}
